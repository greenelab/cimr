version: 2.1
jobs:
  test:
    docker:
      - image: circleci/python:3.7.6
    working_directory: ~/cimr
    resource_class: xlarge
    steps:
      - checkout
      - run:
          name: Install cimr
          command: bash .circleci/install_cimr.sh

      - run:
          name: Parallel Test - SMALL gwas, default chunksize (5m)
          working_directory: ~/cimr/.circleci/dhu_test/gwas/small/
          command: |
            rm -rf submitted_data/ processed_data/ catalog.txt
            cimr processor -process -yaml-file small_gwas.yml
            gunzip -k processed_data/gwas/gwas.txt.gz
            md5sum --check md5.txt
      - run:
          name: Parallel Test - SMALL gwas, chunksize 500
          working_directory: ~/cimr/.circleci/dhu_test/gwas/small/
          command: |
            rm -rf submitted_data/ processed_data/ catalog.txt
            cimr processor -process -yaml-file small_gwas.yml -chunksize 500
            gunzip -k processed_data/gwas/gwas.txt.gz
            md5sum --check md5.txt

      - run:
          name: Parallel Test - SMALL EQTL, default chunksize (5m)
          working_directory: ~/cimr/.circleci/dhu_test/eqtl/small/
          command: |
            rm -rf submitted_data/ processed_data/ catalog.txt
            cimr processor -process -yaml-file eqtl.yml
            gunzip -k processed_data/eqtl/eqtl.txt.gz
            md5sum --check md5.txt
      - run:
          name: Parallel Test - SMALL EQTL, chunksize 5,000
          working_directory: ~/cimr/.circleci/dhu_test/eqtl/small/
          command: |
            rm -rf submitted_data/ processed_data/ catalog.txt
            cimr processor -process -yaml-file eqtl.yml -chunksize 5000
            gunzip -k processed_data/eqtl/eqtl.txt.gz
            md5sum --check md5.txt

      - run:
          name: Download big GWAS file
          working_directory: ~/cimr/.circleci/dhu_test/gwas/big/
          command: |
            wget ftp://share.sph.umich.edu/UKBB_SAIGE_HRC/PheCode_187.2_SAIGE_MACge20.txt.vcf.gz
            mkdir -p submitted_data/gwas/
            mv PheCode_187.2_SAIGE_MACge20.txt.vcf.gz submitted_data/gwas/
            md5sum --check input_md5.txt

      - run:
          name: Parallel Test - BIG gwas, chunksize 500k, 8 CPUs
          working_directory: ~/cimr/.circleci/dhu_test/gwas/big/
          command: |
            rm -rf processed_data/ catalog.txt
            cimr processor -process -yaml-file big_gwas.yml -chunksize 500000 -parallel 8
      - run:
          name: GWAS md5 check
          working_directory: ~/cimr/.circleci/dhu_test/gwas/big/
          command: |
            gunzip -k processed_data/gwas/PheCode_187.2_SAIGE_MACge20.tsv.gz
            md5sum --check md5.txt

      - run:
          name: Download big EQTL file
          working_directory: ~/cimr/.circleci/dhu_test/eqtl/big/
          command: |
            wget https://storage.googleapis.com/gtex_analysis_v7/single_tissue_eqtl_data/all_snp_gene_associations/Brain_Substantia_nigra.allpairs.txt.gz
            mkdir -p submitted_data/eqtl/
            mv Brain_Substantia_nigra.allpairs.txt.gz submitted_data/eqtl/
            #md5sum --check input_md5.txt

      - run:
          name: Parallel Test - BIG EQTL, chunksize 500k, 8 CPUs
          working_directory: ~/cimr/.circleci/dhu_test/eqtl/big/
          command: |
            rm -rf processed_data/ catalog.txt
            cimr processor -process -yaml-file big_eqtl.yml -chunksize 500000 -parallel 8
          no_output_timeout: 20m
      - run:
          name: EQTL md5 check
          working_directory: ~/cimr/.circleci/dhu_test/eqtl/big/
          command: |
            gunzip -k processed_data/eqtl/Brain_Substantia_nigra.allpairs.txt.gz
            md5sum --check md5.txt


workflows:
  version: 2
  test:
    jobs:
      - test
